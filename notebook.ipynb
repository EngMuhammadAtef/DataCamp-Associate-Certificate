{"cells":[{"source":"# Data Scientist Associate Practical Exam Submission\n\nUse this template to complete your analysis and write up your summary for submission.\n","metadata":{},"id":"1e20b471-43f1-4e12-afb1-aa7825d8cc69","cell_type":"markdown"},{"source":"## Task 1 \n1. For every column in the data:\n    - **booking_id** (Nominal): The unique identifier of the booking.\n        - True\n        - 0 missing values\n        \n    - **months_as_member** (Discrete): The number of months as this fitness club member.\n        - True\n        - 0 missing values\n    \n    - **weight** (Continuous): The member's weight in kg, rounded to 2 decimal places. \n        - True\n        - 20 missing values (Replacing missing values with the overall average weight)\n    \n    - **days_before** (Discrete): The number of days before the class the member registered.\n        - False\n        - 0 missing values\n        - There are ' days' part in some rows so we remove it and convert data type to int\n        \n    - **day_of_week** (Nominal): The day of the week of the class. One of “Mon”, “Tue”, “Wed”, “Thu”, “Fri”, “Sat” or “Sun”.\n        - False\n        - 0 missing values\n        - There are ['Wednesday', 'Monday','Fri.'] in some rows so we replace it with ['Wed', 'Mon','Fri'] \n    \n    - **time** (Ordinal): The time of day of the class. Either “AM” or “PM”.\n        - True\n        - 0 missing values\n\n    - **category** (Nominal): The category of the fitness class. One of “Yoga”, “Aqua”, “Strength”, “HIIT”, or “Cycling”.\n        - False\n        - 0 missing values\n        - There are '-' in some rows so we replace it with 'unknown'\n\n    - **attended** (Nominal): Whether the member attended the class (1) or not (0)\n        - True\n        - 0 missing values\n","metadata":{},"id":"836353de-534f-460d-b9ce-e92cc3646c65","cell_type":"markdown"},{"source":"## Task 2\n### Creating a visualization that shows how many bookings attended the class\n![download-5](download-5.png)\n\n![ff00eb1f-194a-44b8-a49f-097dc14ac45d](ff00eb1f-194a-44b8-a49f-097dc14ac45d.png)\n\n**The most observations category of the variable attended is HIIT**\n\nExplaining whether the observations are balanced across categories of the variable attended -> No, Becuase Counting of class 1 is less than class 0..","metadata":{},"id":"0944d9ab-ff5a-4dd3-bd52-e27b91d68581","cell_type":"markdown"},{"source":"## Task 3\n### Describing the distribution of the number of months as a member.\n![3fd52d9e-18a1-4b8f-8ebc-423825ea3eb4](3fd52d9e-18a1-4b8f-8ebc-423825ea3eb4.png)\n\n![download-3](download-3.png)","metadata":{},"id":"c509bc83-41a5-42cf-a865-08dcf8229a16","cell_type":"markdown"},{"source":"## Task 4\n### Describing the relationship between attendance and number of months as a member\n![31a9ab29-ee5f-4434-a7e7-ffd0dc549432](31a9ab29-ee5f-4434-a7e7-ffd0dc549432.png)","metadata":{},"id":"17cca003-71ad-4d7e-989b-09aa51ae0aba","cell_type":"markdown"},{"source":"## Task 5\nThe business wants to predict whether members will attend using the data provided.\n\nThe type of machine learning that this is **classification** problem.\n\nThe attended column is nominal. whether the member attended the class (1) or not (0).","metadata":{},"id":"66e07a44-f276-4516-87ce-e460d3f1a33a","cell_type":"markdown"},{"source":"## Task 6\n### Fitting a baseline model to predict whether members will attend using the data provided","metadata":{},"id":"8b20fa2e-da87-4cf4-9591-157a0837891e","cell_type":"markdown"},{"source":"# Start coding here... \nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\npath = 'fitness_class_modiefied.csv'\ndf = pd.read_csv(path)\ndf = pd.get_dummies(df)\nX, y = df.drop('attended', axis=1), df['attended']\nx_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nprint('Fiiting Logistic Regression...')\nprint('The Score:',lr.score(x_test, y_test))","metadata":{"executionCancelledAt":null,"executionTime":748,"lastExecutedAt":1692891688402,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here... \nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\npath = 'fitness_class_modiefied.csv'\ndf = pd.read_csv(path)\ndf = pd.get_dummies(df)\nX, y = df.drop('attended', axis=1), df['attended']\nx_train, x_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\nlr = LogisticRegression()\nlr.fit(x_train, y_train)\nprint('Fiiting Logistic Regression...')\nprint('The Score:',lr.score(x_test, y_test))","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"id":"76b4446c-9c17-4aa7-8119-8d33c51a6593","cell_type":"code","execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":"Fiiting Logistic Regression...\nThe Score: 0.7666666666666667\n"}]},{"source":"## Task 7\n### Fitting a comparison model to predict whether members will attend using the data provided","metadata":{},"id":"b7f0dcc4-98c7-43fe-8ee2-629aac60c421","cell_type":"markdown"},{"source":"# Start coding here... \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nparam_grid = {\n    'random_state':[0],\n    'max_depth': [20],\n    'min_samples_leaf': [3],\n    'min_samples_split': [20],\n    'n_estimators': [400]\n}\n\nrf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)\n\nrf.fit(x_train, y_train)\nprint('Fitting Random Forest Classifier...')\nprint(rf.best_estimator_)\nprint('The Score:',rf.score(x_test, y_test))","metadata":{"executionCancelledAt":null,"executionTime":3806,"lastExecutedAt":1692891692208,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here... \nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nparam_grid = {\n    'random_state':[0],\n    'max_depth': [20],\n    'min_samples_leaf': [3],\n    'min_samples_split': [20],\n    'n_estimators': [400]\n}\n\nrf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=param_grid, cv=5)\n\nrf.fit(x_train, y_train)\nprint('Fitting Random Forest Classifier...')\nprint(rf.best_estimator_)\nprint('The Score:',rf.score(x_test, y_test))","outputsMetadata":{"0":{"height":97,"type":"stream"}}},"id":"3d5953c8-9f51-426c-a597-b41bd742e4d1","cell_type":"code","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":"Fitting Random Forest Classifier...\nRandomForestClassifier(max_depth=20, min_samples_leaf=3, min_samples_split=20,\n                       n_estimators=400, random_state=0)\nThe Score: 0.78\n"}]},{"source":"## Task 8\n\nWe used logistic regression because it is a type of regression analysis that is used to predict **the probability** of a binary outcome (such as attended \\ not attended) based on one or more input variables1. It uses a logistic function to transform the odds of the outcome into a value between 0 and 1\n\nWe used random forest because it is a machine learning method that uses **multiple decision trees** to make predictions. We use random forest because it can **improve the accuracy** and **reduce overfitting** compared to a single decision tree.","metadata":{},"id":"5cec4b2d-86fd-4ce3-9f9c-e9ab2ec0e436","cell_type":"markdown"},{"source":"## Task 9\n**Comparing the performance of the two models using 'train_test_split' to split data into train-set and test-set to show score of models**","metadata":{},"id":"84fc2a09-ea39-4a6f-85b2-5d17957e1ac5","cell_type":"markdown"},{"source":"# Start coding here... \nprint('Logistic Regression')\nprint('The Score:',lr.score(x_test, y_test))\nprint()\nprint('Random Forest')\nprint('The Score:',rf.score(x_test, y_test))","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1692891692264,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Start coding here... \nprint('Logistic Regression')\nprint('The Score:',lr.score(x_test, y_test))\nprint()\nprint('Random Forest')\nprint('The Score:',rf.score(x_test, y_test))","outputsMetadata":{"0":{"height":117,"type":"stream"}}},"id":"246f2368-09ae-4cac-bdb5-7daacb0b2faf","cell_type":"code","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":"Logistic Regression\nThe Score: 0.7666666666666667\n\nRandom Forest\nThe Score: 0.78\n"}]},{"source":"## Task 10\n### Explaining which model performs better and why\n\n**Random forest model is better than logistic regression**\n\nRandom forest model and logistic regression are two different methods for classification problems. Random forest model uses an ensemble of decision trees to make predictions, while logistic regression uses a logistic function to estimate the probability of each class.\n\nSome advantages of random forest model over logistic regression are:\n\n- It can handle missing values, outliers, and non-linear relationships.\n- It can classify data into more than two categories with just one model.\n- It can capture complex interactions among features.\n\nSome disadvantages of random forest model compared to logistic regression are:\n\n- It requires more computational resources and time to train and test.\n- It is less interpretable and explainable than logistic regression.\n- It may overfit the data if the number of trees is too large or the depth is too high.","metadata":{},"id":"feb9e1eb-8913-43b8-a280-a369cf10631e","cell_type":"markdown"},{"source":"## ✅  When you have finished...\n- Publish your Workspace using the option on the left\n- Check the published version of your report:\n\t- Can you see everything you want us to grade?\n    - Are all the graphics visible?\n- Review the grading rubric. Have you included everything that will be graded?\n- Head back to the [Certification dashboard](https://app.datacamp.com/certification) to submit your practical exam","metadata":{},"id":"c42a2f84-876d-4002-9d9b-990873351e5f","cell_type":"markdown"}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}